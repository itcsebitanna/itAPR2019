3 B. IMPLEMENTATION OF LEXICAL ANALYZER USING LEX TOOL
AIM:

To write a program for implementing a Lexical analyser using LEX tool in Linux platform.

INTRODUCTION:
  	THEORY:
1.	A language for specifying lexical analyzer.
2.	There is a wide range of tools for construction of lexical analyzer. The majority of these tools are based on regular expressions.
3.	The one of the traditional tools of that kind is lex.
LEX:
1.	The lex is used in the manner depicted. A specification of the lexical analyser is preferred by creating a program lex.1 in the lex language.
2.	Then lex.1 is run through the lex compiler to produce a ‘c’ program lex.yy.c.
3.	The program lex.yy.c consists of a tabular representation of a transition diagram constructed from the regular expression of lex.1 together with a standard routine that uses table of recognize leximes.
4.	Lex.yy.c is run through the ‘C’ compiler to produce as object program a.out, which is the lexical analyzer that transform as input stream into sequence of tokens.

ALGORITHM:

1.	Lex program contains three sections: definitions, rules, and user subroutines. Each section must be separated from the others by a line containing only the    delimiter, %%. 
The format is as follows:
 	definitions
%%
rules
%%
user_subroutines
2.	In definition section, the variables make up the left column, and their definitions make up the right column. Any C statements should be enclosed in %{..}%. Identifier is defined such that the first letter of an identifier is alphabet and remaining letters are alphanumeric.
3.	In rules section, the left column contains the pattern to be recognized in an input file to yylex(). The right column contains the C program fragment executed when that pattern is recognized. The various patterns are keywords, operators, new line character, number, string, identifier, beginning and end of block, comment statements, preprocessor directive statements etc.
4.	Each pattern may have a corresponding action, that is, a fragment of C source code to execute when the pattern is matched.
5.	When yylex() matches a string in the input stream, it copies the matched text to an external character array, yytext, before it executes any actions in the rules section.

6.	In user subroutine section, main routine calls yylex(). yywrap() is used to get more input.
7.	The lex command uses the rules and actions contained in file to generate a program, lex.yy.c, which can be compiled with the cc command. That program can then receive input, break the input into the logical pieces defined by the rules in file, and run program fragments contained in the actions in file.

PROGRAM
%{
#include<stdio.h>
int e,k,c,d,i,s;
%}
%%
stdio.h|include|void|main|int|float|double|scanf|char|printf { printf("\n%s keyword",yytext); i++; }
[a-z][a-z A-Z 0-9]* { printf("\n%s identifier",yytext); k++; }
[0-9]* { printf("\n%s digit",yytext); e++; }
[+|-|*|/|=]* { printf("\n%s operator",yytext); c++; }
[;|:|(|)|{|}|"|'|,|\n|\t]* { printf("\n%s delimiter",yytext); d++; }
[#|<|>|%]* { printf("\n%s symbols",yytext); s++; }
%%
int main()
{
yyin=fopen("text.c","r");
yylex();
printf("\n identifier %d",k);
printf("\n symbols %d",s);
printf("\n digits %d",e);
printf("\n operator %d",c);
printf("\n keywords %d",i);
printf("\n delimiter %d",d);
yylex();
return 1;
}
int yywrap()
{
return 1;
}
Output:
Text.c
#include<stdio.h>
main()
{
printf(“hai”);
}
Output:
# symbols
include keywords
< delimiter
stdio.h keywords
> delimiter
{ delimiter
Printf keywords
( delimiter
“ delimiter
Hai identifier
“ delimiter
) delimiter
; delimiter
} delimiter
